07/20/2021 11:31:27 AM: [ COMMAND: D:/github/EmpatheticDialogues/retrieval_train.py --model-dir output ]
07/20/2021 11:31:27 AM: [ ---------------------------------------------------------------------------------------------------- ]
07/20/2021 11:31:27 AM: [ CONFIG:
{
    "batch_size": 32,
    "bert_add_transformer_layer": false,
    "bert_dim": 512,
    "cuda": false,
    "dailydialog_folder": null,
    "dataset_name": "reddit",
    "dict_max_words": 250000,
    "display_iter": 250,
    "embeddings": null,
    "embeddings_size": 300,
    "empchat_folder": null,
    "epoch_start": 0,
    "fasttext": null,
    "fasttext_path": null,
    "fasttext_type": null,
    "hits_at_nb_cands": 100,
    "learn_embeddings": false,
    "learning_rate": null,
    "load_checkpoint": null,
    "log_file": "output\\20210720-64a5f771.txt",
    "max_hist_len": 1,
    "max_sent_len": 100,
    "model": null,
    "model_dir": "output",
    "model_file": "output\\20210720-64a5f771.mdl",
    "model_name": "20210720-64a5f771",
    "n_layers": 6,
    "no_shuffle": false,
    "normalize_emb": false,
    "normalize_sent_emb": false,
    "num_epochs": 1000,
    "optimizer": "adamax",
    "pretrained": null,
    "random_seed": 92179,
    "reactonly": false,
    "reddit_folder": null,
    "rm_long_contexts": false,
    "rm_long_sent": false,
    "stop_crit_num_epochs": -1,
    "transformer_dim": 512,
    "transformer_dropout": 0,
    "transformer_n_heads": 8
} ]
